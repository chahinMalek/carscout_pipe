
x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: airflow/Dockerfile
  env_file:
    - .env.docker
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
    AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: "60"
    AIRFLOW__LOGGING__LOGGING_LEVEL: "INFO"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    AIRFLOW__WEBSERVER__RBAC: "true"
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"

    PYTHONPATH: /opt/app
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./:/opt/app
    - ./data:/opt/app/data
    - airflow-logs:/opt/airflow/logs
  depends_on:
    airflow-postgres:
      condition: service_healthy

services:

  airflow-postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "
        airflow db migrate &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true
      "
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always

  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    restart: always

volumes:
  airflow-db:
  airflow-logs:
